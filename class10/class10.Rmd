---
title: "class10"
author: "Cindy Tran"
date: "2/6/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Analysis of Human Breast Cancer Cells

# Section 1: Exploratory data analysis

First, we will import our data that we got from the class website:
```{r}
wisc.df <- read.csv("WisconsinCancer.csv")
#To look at the first 6 rows of the data set:
head(wisc.df)
# The id column is the identification number of the patients. The diagnosis column is the diagnosis that the doctors in Wisconsin already gave these patients. It's weird because there is a column labeled 'x' that only includes 'NA'.
```

We are now going to create a matrix that does not include the 'id', 'diagnosis', and the 'x' column, the funky things that we are going to ignore. This means the matrix will include columns 3 to 32.
```{r}
wisc.data <- as.matrix(wisc.df[,3:32])
#check what you just did
head(wisc.data)
```

Next we will set the row names to be the id of the patients. 
```{r}
row.names(wisc.data) <- wisc.df$id
#Let's check
head(wisc.data)
```

Q1. How many observations are in this data set?
```{r}
nrow(wisc.data)
#569
```

Q2. How many of the observations have a malignant diagnosis?
```{r}
table(wisc.df$diagnosis)
# 357 Benign and 212 Malignant
```

Q3. How many variables/features in the data are suffixed with _mean?
```{r}
grep("_mean", colnames(wisc.data), value=TRUE)
# Means the first 10 entries include the "_mean". The value gives you the names of the ones that has this.

length(grep("_mean", colnames(wisc.data), value=TRUE))
# gives you that there are 10 places where this occurs
```

# Section 2: Principal Component Analysis

Before we turn to PCA, we need to think or consider whether we should SCALE our input. The input variables use different units of measurement and have significantly different variances.

Do this by checking the means and standard deviations of the columns:
```{r}
round(colMeans(wisc.data), 2)
round(apply(wisc.data,2,sd), 2)
# 2 represents columns. 1 would be rows. The 'sd' is the standard deviation column.
```

Yes, we need to SCALE our data. Set scale=TRUE!

Perform PCA on wisc.data by completing the following code:
```{r}
wisc.pr <- prcomp(wisc.data, scale= TRUE)
summary(wisc.pr)
# Remember, PC1 is more important that PC2 and so on...
```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?
  
  The first PC captures 44.27% of the original variance.
  
> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?
  
  PC1, PC2, and PC3 gives you 72.636%.
  
> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?
  
  PC1 to PC7 gives you 91.01%.
  
Let's make some figures...

```{r}
biplot(wisc.pr)
# This is not a pretty plot. It is useless.
```

We have to make our own PC1 vs PC2 plot and lets color by the expert's diagnosis. 
```{r}
attributes(wisc.pr)
# Tells you all the stuff that's in the results and we want to use the 'x' because it is the scores on our PC components.
```

Our graph of PC1 vs. PC2
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=wisc.df$diagnosis, xlab = "PC1", ylab = "PC2")
# Draw a line at 0, horizontal and vertical
abline(h=0, col="gray", lty=2)
abline(v=0, col="gray", lty=2)
```

Let's graph PC1 vs. PC3
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,3], col=wisc.df$diagnosis, xlab = "PC1", ylab = "PC2")
# Draw a line at 0, horizontal and vertical
abline(h=0, col="gray", lty=2)
abline(v=0, col="gray", lty=2)
```

## CLuster in PC space

First let's see if we can cluster the original data...

With Heirarichal clustering...
```{r}
wisc.hc <- hclust(dist(wisc.data))
plot(wisc.hc)
```
With k-means....
```{r}
wisc.km <- kmeans(wisc.data, centers = 2, nstart = 20)
table(wisc.km$cluster)
```

Let's see if PCA improves or degrades the performance of hierarchical clustering.

Using the minimum number of principal components required to describe at least 90% of the variability in the data, create a hierarchical clustering model with the linkage method="ward.D2". We use Wardâ€™s criterion here because it is based on multidimensional variance like principal components analysis. Assign the results to wisc.pr.hclust.
```{r}
wisc.pr.hclust <- hclust( dist(wisc.pr$x[,1:3]), method="ward.D2" )
plot(wisc.pr.hclust)
#This one looks so much better. You could see the two main groups.
cutree(wisc.pr.hclust, k=4)
#Let's cut this into 4 groups
```

To get our clusters out of this tree we need to CUT it with the `cutree()` function.

```{r}
grps3 <- cutree(wisc.pr.hclust, k=3)
table(grps3)
# 111 in group 1, 92 in group 2 and 366 in group 3
```

Now let's plot this into groups..
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=grps3)
```

We can use the table function to compare the $diagnosis vector with our cluster results vector.
```{r}
table(grps3, wisc.df$diagnosis)
```

Change it to two groups...
```{r}
grps2 <- cutree(wisc.pr.hclust, k=2)
table(grps2)

plot(wisc.pr$x[,1], wisc.pr$x[,2], col=grps2)
table(grps2, wisc.df$diagnosis)
# This is telling me that in my cluster 1 I have 24 benign and 179 malignant so 24 are misclassified. Cluster 2 has 333 benign and 33 malignant soe 33 cases are misdiagnosed. This doesn't mean that the doctors were wrong, our program could be wrong, we don't know
```

## Section 7: Prediction
We will use the predict function that will take our PCA model from before and new cancer cell data and project that data into our PCA space.
Read in new data:
```{r}
new <- read.csv("new-samples-CSV.csv")
new
```
Now use the `predict()` function with our previous PCA model and new data...
```{r}
npc <- predict(wisc.pr, newdata = new)
npc
```

Now we want to add them to our plot:
```{r}
plot(wisc.pr$x[,1], wisc.pr$x[,2], col=wisc.df$diagnosis)
  #prints the plot same as before
points(npc[,1], npc[,2], col= "blue", pch=15, cex= 3)
  #adds the two squares that show our new data of the two patients
text(npc[,1], npc[,2], labels = c(1,2), col="white")
  #adds the labels of patient 1 and 2
```
From this plot, we want to prioritize patient 2 because it's data falls with the malignant category of our data.
